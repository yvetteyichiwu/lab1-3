{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Please do not change this cell because some hidden tests might depend on it.\n",
    "import os\n",
    "\n",
    "# Otter grader does not handle ! commands well, so we define and use our\n",
    "# own function to execute shell commands.\n",
    "def shell(commands, warn=True):\n",
    "    \"\"\"Executes the string `commands` as a sequence of shell commands.\n",
    "     \n",
    "       Prints the result to stdout and returns the exit status. \n",
    "       Provides a printed warning on non-zero exit status unless `warn` \n",
    "       flag is unset.\n",
    "    \"\"\"\n",
    "    file = os.popen(commands)\n",
    "    print (file.read().rstrip('\\n'))\n",
    "    exit_status = file.close()\n",
    "    if warn and exit_status != None:\n",
    "        print(f\"Completed with errors. Exit status: {exit_status}\\n\")\n",
    "    return exit_status\n",
    "\n",
    "shell(\"\"\"\n",
    "ls requirements.txt >/dev/null 2>&1\n",
    "if [ ! $? = 0 ]; then\n",
    " rm -rf .tmp\n",
    " git clone https://github.com/cs187-2021/lab1-3.git .tmp\n",
    " mv .tmp/tests ./\n",
    " mv .tmp/requirements.txt ./\n",
    " rm -rf .tmp\n",
    "fi\n",
    "pip install -q -r requirements.txt\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84aa2599",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "%%latex\n",
    "\\newcommand{\\vect}[1]{\\mathbf{#1}}\n",
    "\\newcommand{\\cnt}[1]{\\sharp(#1)}\n",
    "\\newcommand{\\argmax}[1]{\\underset{#1}{\\operatorname{argmax}}}\n",
    "\\newcommand{\\softmax}{\\operatorname{softmax}}\n",
    "\\newcommand{\\Prob}{\\Pr}\n",
    "\\newcommand{\\given}{\\,|\\,}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\renewcommand{\\vect}[1]{\\mathbf{#1}}\n",
    "\\renewcommand{\\cnt}[1]{\\sharp(#1)}\n",
    "\\renewcommand{\\argmax}[1]{\\underset{#1}{\\operatorname{argmax}}}\n",
    "\\renewcommand{\\softmax}{\\operatorname{softmax}}\n",
    "\\renewcommand{\\Prob}{\\Pr}\n",
    "\\renewcommand{\\given}{\\,|\\,}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove_for_latex"
    ]
   },
   "source": [
    "# CS187\n",
    "## Lab 1-3 – Naive Bayes classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you'll apply the naive Bayes method to the _Federalist_ papers' authorship attribution problem.\n",
    "\n",
    "After this lab, you should be able to\n",
    "\n",
    "* Derive the basic equations for the naive Bayes classification method;\n",
    "* Estimate the parameters for the naive Bayes model;\n",
    "* Determine where use of the \"log trick\" is indicated, and apply it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New bits of Python used for the first time in the _solution set_ for this lab, and which you may therefore find useful:\n",
    "\n",
    "* [`math.log2`](https://docs.python.org/3.8/library/math.html#math.log2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation – Loading packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import json\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use('tableau-colorblind10')\n",
    "import torch\n",
    "import wget\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0% [                                                          ]     0 / 16713\r",
      " 49% [............................                              ]  8192 / 16713\r",
      " 98% [........................................................  ] 16384 / 16713\r",
      "100% [..........................................................] 16713 / 16713"
     ]
    }
   ],
   "source": [
    "# Download and read the Federalist data from the json file\n",
    "os.makedirs('data', exist_ok=True)\n",
    "wget.download('https://github.com/nlp-course/data/raw/master/Federalist/federalist_data.json', out='data/')\n",
    "with open('data/federalist_data.json', 'r') as fin:\n",
    "    dataset = json.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'authors': 'Hamilton',\n",
       "  'counts': [9, 6, 2, 0],\n",
       "  'number': '1',\n",
       "  'title': 'General Introduction'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': [2, 4, 7, 0],\n",
       "  'number': '6',\n",
       "  'title': 'Concerning Dangers from Dissensions Between the States'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': [13, 11, 9, 0],\n",
       "  'number': '7',\n",
       "  'title': 'The Same Subject Continued: Concerning Dangers from Dissensions Between the States'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': [11, 3, 1, 0],\n",
       "  'number': '8',\n",
       "  'title': 'The Consequences of Hostilities Between the States'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': [9, 4, 3, 0],\n",
       "  'number': '9',\n",
       "  'title': 'The Union as a Safeguard Against Domestic Faction and Insurrection'},\n",
       " {'authors': 'Madison',\n",
       "  'counts': [18, 0, 4, 0],\n",
       "  'number': '10',\n",
       "  'title': 'The Same Subject Continued: The Union as a Safeguard Against Domestic Faction and Insurrection'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': [5, 6, 5, 0],\n",
       "  'number': '11',\n",
       "  'title': 'The Utility of the Union in Respect to Commercial Relations and a Navy'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': [12, 7, 9, 0],\n",
       "  'number': '12',\n",
       "  'title': 'The Utility of the Union in Respect to Revenue'},\n",
       " {'authors': 'Hamilton',\n",
       "  'counts': [3, 2, 9, 0],\n",
       "  'number': '13',\n",
       "  'title': 'Advantage of the Union in Respect to Economy in Government'},\n",
       " {'authors': 'Madison',\n",
       "  'counts': [17, 0, 0, 1],\n",
       "  'number': '14',\n",
       "  'title': 'Objections to the Proposed Constitution from Extent of Territory Answered'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As before, we extract the papers by either of Madison and Hamilton\n",
    "# to serve as training data.\n",
    "training = list(filter(lambda ex: ex['authors'] in ['Madison', 'Hamilton'],\n",
    "                       dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Naive Bayes method reviewed\n",
    "A quick review of the Naive Bayes (NB) method for text classification: In classification tasks, we're given a representation of some text as a vector $\\mathbf{x} = \\langle x_1, x_2, \\ldots, x_m \\rangle$ of feature values, and we'd like to determine which of a set of classes $\\{ y_1, y_2, \\ldots, y_k \\}$ the text should be classified as. \n",
    "\n",
    "> In the case at hand, the Federalist Papers, for a given document, we'll take $\\mathbf{x} = \\langle x_1, x_2, \\ldots, x_m \\rangle$ to be the sequence of words in the document, so each $x_i$ corresponds to a single word token.\n",
    "\n",
    "We might naturally think to choose that class that has the highest probability of being correct, that is, the class $y_i$ that maximizes $Pr(y_i \\mid \\mathbf{x})$.\n",
    "\n",
    "By Bayes rule (this is the \"Bayes\" part in the name \"Naive Bayes\"), \n",
    "\n",
    "\\begin{align*}\n",
    "\\argmax{i} \\Prob(y_i \\given \\vect{x}) \n",
    "&= \\argmax{i} \\frac{\\Prob(\\vect{x} \\given y_i) \\cdot \\Prob(y_i)}{\\Prob(\\vect{x})} \\\\\n",
    "&= \\argmax{i} \\Prob(\\vect{x} \\given y_i) \\cdot \\Prob(y_i)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question**: Why can we drop the denominator in the last step of this derivation?\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: open_response_denominator\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0399972",
   "metadata": {},
   "source": [
    "_Because Pr(x) will be constant as we compute through different y_i, as x is the document vector and we are only working with one document at a time._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "We use the following terminology: $\\Prob(y_i)$ is the _prior probability_. $\\Prob(\\vect{x} \\given y_i)$ is the _likelihood_. \n",
    "$\\Prob(y_i \\given \\vect{x})$ is the _posterior probability_.\n",
    "\n",
    "By the chain rule, \n",
    "\n",
    "\\begin{align*}\n",
    "\\Prob(\\vect{x} \\given y_i) &= \\Prob(x_1, \\ldots, x_m \\given y_i) \\\\\n",
    "&= \\Prob(x_1 \\given y_i) \\cdot \\Prob(x_2, \\ldots, x_m \\given x_1, y_i) \\\\\n",
    "&= \\Prob(x_1 \\given y_i) \\cdot \\Prob(x_2 \\given x_1, y_i) \\cdot \\Prob(x_3, \\ldots,\n",
    "x_m \\given x_1, x_2, y_i) \\\\\n",
    "\\cdots &= \\prod_{j=1}^m \\Prob(x_j \\given x_1, \\ldots, x_{j-1}, y_i)\n",
    "\\end{align*}\n",
    "\n",
    "We further assume that each feature $x_i$ is independent of all the others given the class. (That's the \"naive\" part.) So \n",
    "\n",
    "$$\n",
    "\\Prob(x_j \\given x_1, \\ldots, x_{j-1}, y_i) \\approx \\Prob(x_j \\given y_i)\n",
    "$$\n",
    "\n",
    "Using this approximation, we'll calculate instead the class as per the following maximization:\n",
    "\n",
    "$$\n",
    "\\argmax{i} \\Prob(y_i \\given \\vect{x}) \\approx \\argmax{i} \\Prob(y_i) \\cdot \\prod_{j=1}^m \\Prob(x_j \\given y_i)\n",
    "$$\n",
    "\n",
    "> This independence assumption, in the text case, amounts to ignoring the order and even the cooccurence of words in a document, a quite aggressive and unrealistic independence assumption indeed.\n",
    "\n",
    "All we need, then, for the Naive Bayes classification method is values for $\\Prob(y_i)$ and $\\Prob(x_j \\given y_i)$ for each feature $x_j$ and each class $y_i$. These constitute the parameters of the model, which we will learn from a training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes for the Federalist papers\n",
    "\n",
    "In applying Naive Bayes to an example in the Federalist dataset, we'll take the $x_i$ to be the _tokens in the example_. To make the calculations easier, in this lab, we won't use _all_ of the tokens, just the tokens of the four word types we've been attending to, but in an actual application of NB, we'd use (essentially) all of the word types. As a reminder,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['on', 'upon', 'there', 'whilst']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the two class labels are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Hamilton', 'Madison']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating the prior probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Let's start with the prior probabilities $\\Prob(y_i)$. In our case, there are only two class labels, for Hamilton and Madison. We estimate the probability of a class $y_i$ by simply counting the proportion of examples that are labeled with that class. (This estimate is the *sample probability*, which is also referred to as the *maximum likelihood estimate* for reasons we'll skip for the moment.) That is, we estimate \n",
    "\n",
    "$$ \\Prob(y_i) \\approx \\frac{\\cnt{y_i}}{N} $$\n",
    "\n",
    "where $N$ is the number of training examples, and $\\cnt{y_i}$ is the number of training examples of class $y_i$.\n",
    "\n",
    "In the cell below, write code to count how many of the training examples are labeled with Hamilton and how many are labeled with Madison. Use these to provide estimates of the Hamilton and Madison prior probabilities.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: priors\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO - Calculate the prior probabilities for Madison and Hamilton as floats.\n",
    "prior_madison = len(list(filter(lambda ex: ex['authors'] in ['Madison'],\n",
    "                       training)))/len(training)\n",
    "prior_hamilton = len(list(filter(lambda ex: ex['authors'] in ['Hamilton'],\n",
    "                       training)))/len(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "388a7942",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"priors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Madison  prior: 0.2273\n",
      "Hamilton prior: 0.7727\n"
     ]
    }
   ],
   "source": [
    "print(f\"Madison  prior: {prior_madison:.4f}\\n\"\n",
    "      f\"Hamilton prior: {prior_hamilton:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question:** What do these probabilities tell us about how we might predict the class of a _Federalist_ document _prior_ to looking at the actual content of the document? (That's why these probabilities are called \"priors\".)\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: open_response_priors\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87a1f76",
   "metadata": {},
   "source": [
    "_All else equal, we are more likely to predict that Hamilton is the author, since the prior probability for Hamilton is greater._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "## Estimating the likelihood probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the likelihood probabilities, the conditional probability of a word given a class. For each likelihood $\\Prob(x_j \\given y_i)$, we need to estimate a value. We'll do so by simply counting the number of training examples with feature value $x_j$ that are labeled $y_i$ (notated as $\\cnt{x_j, y_i}$) as a proportion of the overall number of words labeled as $y_i$, that is,\n",
    "\n",
    "$$ \\Prob(x_j \\given y_i) \\approx \\frac{\\cnt{x_j, y_i}}{\\sum_k \\cnt{x_k, y_i}} $$\n",
    "\n",
    "Again, for the text case, each token counts as an instance of the corresponding word type in a training example. Note that $\\sum_k \\cnt{x_k, y_i}$ is not the same as $\\cnt{y_i}$.\n",
    " \n",
    "We've provided a small table that shows, for each label (author) and each of the four word types of interest, how many tokens of the type occurred in training examples with that label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                on    upon   there  whilst\n",
      "Hamilton       390     377     369       1\n",
      "Madison        308       7      32      12\n"
     ]
    }
   ],
   "source": [
    "def counts(dataset, label, index):\n",
    "    \"\"\"Returns the total count for `index` for examples with the \n",
    "       given `label`\"\"\"\n",
    "    return sum([example['counts'][index] \n",
    "                for example in dataset \n",
    "                if example['authors'] == label])\n",
    "\n",
    "# print a table header\n",
    "print(f\"{'':10}\", end=\"\")\n",
    "for i in range(4):\n",
    "    print(f\"{keywords[i]:>8}\", end=\"\")\n",
    "print()\n",
    "# print table entries for each label\n",
    "for label in classes:\n",
    "    print(f\"{label:10}\", end=\"\")\n",
    "    for i in range(4):\n",
    "        print(f\"{counts(training, label, i):8}\", end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Given the counts in this table, what would an estimate be for the probability that a given word would be \"whilst\" given that the document was authored by Madison, that is, $\\Prob(\\mathrm{whilst} \\given \\mathrm{Madison})$?\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: prob_whilst_madison\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.033426183844011144"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO - Define this variable to be the specified probability.\n",
    "prob_whilst_madison = counts(training, 'Madison', 3)/sum(counts(training, 'Madison', index) for index in range(4))\n",
    "prob_whilst_madison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "226b9c40",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"prob_whilst_madison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "What about the probability $\\Prob(\\mathrm{on} \\given \\mathrm{Hamilton})$?\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: prob_on_hamilton\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34300791556728233"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO - Define this variable to be the specified probability.\n",
    "prob_on_hamilton = counts(training, 'Hamilton', 0)/sum(counts(training, 'Hamilton', index) for index in range(4))\n",
    "prob_on_hamilton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9af0e975",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"prob_on_hamilton\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Consider a sample text \n",
    "\n",
    "> **whilst** depending neither **on** the American government nor **on** the British\n",
    "\n",
    "What would the Naive Bayes method estimate be for the likelihood of this sentence if it was by Hamilton? By Madison? (You should of course ignore all the tokens in our little sample text except for tokens of the four keyword types. (We've boldfaced their occurrences.) With a full-blown NB analysis, we'd be using *all* of the words in the text.)\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: likelihoods\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_on_madison = counts(training, 'Madison', 0)/sum(counts(training, 'Madison', index) for index in range(4))\n",
    "prob_whilst_hamilton = counts(training, 'Hamilton', 3)/sum(counts(training, 'Hamilton', index) for index in range(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO - Define the variables to be the corresponding likelihood probabilities.\n",
    "likelihood_hamilton = prob_whilst_hamilton * (prob_on_hamilton ** 2)\n",
    "likelihood_madison = prob_whilst_madison * (prob_on_madison ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "03f0f228",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"likelihoods\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Madison  likelihood: 0.024604\n",
      "Hamilton likelihood: 0.000103\n"
     ]
    }
   ],
   "source": [
    "print(f\"Madison  likelihood: {likelihood_madison:4f}\\n\"\n",
    "      f\"Hamilton likelihood: {likelihood_hamilton:4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We're almost there. We simply need to combine the prior probabilities and the likelihood probabilities for each class to form the posterior, and select the largest one. As a reminder, we don't actually calculate the posterior _probability_ because we aren't dividing through by $\\Prob(\\vect{x})$. Instead, we get something like a posterior _score_.\n",
    "\n",
    "Calculate the posteriors for the two classes, and then specify which class – Hamilton or Madison – the NB method would predict for the sample text.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: posteriors\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO - Define the variables to be the corresponding posterior probabilities, \n",
    "#       and the classification of the sample phrase.\n",
    "posterior_madison = prior_madison * likelihood_madison\n",
    "posterior_hamilton = prior_hamilton * likelihood_hamilton\n",
    "sample_classification = 'Madison' if posterior_madison > posterior_hamilton else 'Hamilton'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "85eda02c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"posteriors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Madison  posterior: 0.005592\n",
      "Hamilton posterior: 0.000080\n",
      "Sample classification: Madison\n"
     ]
    }
   ],
   "source": [
    "print(f\"Madison  posterior: {posterior_madison:4f}\\n\"\n",
    "      f\"Hamilton posterior: {posterior_hamilton:4f}\\n\"\n",
    "      f\"Sample classification: {sample_classification}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question:** Is the NB-predicted classification the same as or different from the classification based on the priors? Why?\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: open_response_nb_v_priors\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e19df9b",
   "metadata": {},
   "source": [
    "_No, the priors predicted Hamilton instead Madison. This is because P(whilst|Hamilton) is very low._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "## A practical issue\n",
    "\n",
    "The computations of what we've been calling the posterior scores\n",
    "$$\\Prob(y_i \\given \\vect{x}) \\approx \\Prob(y_i) \\cdot \\prod_{j=1}^m \\Prob(x_j \\given y_i)$$\n",
    "involve the multiplication of many extremely small numbers. This is a recipe for [_arithmetic underflow_](https://en.wikipedia.org/wiki/Arithmetic_underflow), leading to garbage outputs.\n",
    "\n",
    "Instead, rather than maximizing the posterior, we can maximize its logarithm. Since the logarithm function is monotonic (see the next cell for a figure), whichever $i$ maximizes the posterior maximizes its log as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def log_plot():\n",
    "    x = torch.linspace(1e-10, 1, 100)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(x, torch.log2(x), label = \"log_2\")\n",
    "    plt.title(\"Monotonicity of logarithm\")\n",
    "    plt.legend()\n",
    "    \n",
    "log_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The log of the posterior is\n",
    "$$\\log \\left(\\Prob(y_i) \\cdot \\prod_{j=1}^m \\Prob(x_j \\given y_i)\\right)\n",
    "      = \\log\\Prob(y_i) + \\sum_{j=1}^m \\log\\Prob(x_j \\given y_i)$$\n",
    "so that the calculation now involves the sum of a bunch of numbers rather than the product. In practice, this computation is much more robust.\n",
    "\n",
    "> A log-of-probability value is referred to, colloquially if not quite accurately, as a *logit*, because of a resemblance to the values of [the logit function](https://en.wikipedia.org/wiki/Logit).\n",
    "\n",
    "Calculate the log of the posterior for Madison for the sample text by summing up all of the pertinent logits, and similarly for Hamilton. Use the base 2 logarithm.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: log_posteriors\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO - Calculate the log of the posterior for Madison by summing up all \n",
    "#       of the pertinent parts.\n",
    "log_posterior_madison = math.log2(prior_madison) + math.log2(prob_whilst_madison) + math.log2(prob_on_madison) * 2\n",
    "log_posterior_hamilton = math.log2(prior_hamilton) + math.log2(prob_whilst_hamilton) + math.log2(prob_on_hamilton) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "43077034",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"log_posteriors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Madison  log posterior:   -7.482\n",
      "Hamilton log posterior:  -13.610\n"
     ]
    }
   ],
   "source": [
    "print(f\"Madison  log posterior: {log_posterior_madison:8.3f}\\n\"\n",
    "      f\"Hamilton log posterior: {log_posterior_hamilton:8.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question:** Which one of the two is larger? Does this accord with your expectation?\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: open_response_posterior\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fb826d",
   "metadata": {},
   "source": [
    "_The log of the posterior for Madison is larger, which is expected because the posterior for Madison in larger and the log function is monotonic increasing._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "# Lab debrief – for consensus submission only\n",
    "\n",
    "**Question:** We're interested in any thoughts your group has about this lab so that we can improve this lab for later years, and to inform later labs for this year. Please list any issues that arose or comments you have to improve the lab. Useful things to comment on include the following: \n",
    "\n",
    "* Was the lab too long or too short?\n",
    "* Were the readings appropriate for the lab? \n",
    "* Was it clear (at least after you completed the lab) what the points of the exercises were? \n",
    "* Are there additions or changes you think would make the lab better?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: open_response_debrief\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a37b13",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "# End of lab 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526a85a3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a2b1f74b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong>likelihoods:</strong></p>\n",
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    \n",
       "\n",
       "<p><strong>log_posteriors:</strong></p>\n",
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    \n",
       "\n",
       "<p><strong>posteriors:</strong></p>\n",
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    \n",
       "\n",
       "<p><strong>priors:</strong></p>\n",
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    \n",
       "\n",
       "<p><strong>prob_on_hamilton:</strong></p>\n",
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    \n",
       "\n",
       "<p><strong>prob_whilst_madison:</strong></p>\n",
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    \n",
       "\n"
      ],
      "text/plain": [
       "likelihoods:\n",
       "\n",
       "    All tests passed!\n",
       "    \n",
       "\n",
       "log_posteriors:\n",
       "\n",
       "    All tests passed!\n",
       "    \n",
       "\n",
       "posteriors:\n",
       "\n",
       "    All tests passed!\n",
       "    \n",
       "\n",
       "priors:\n",
       "\n",
       "    All tests passed!\n",
       "    \n",
       "\n",
       "prob_on_hamilton:\n",
       "\n",
       "    All tests passed!\n",
       "    \n",
       "\n",
       "prob_whilst_madison:\n",
       "\n",
       "    All tests passed!\n",
       "    \n"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "title": "CS187 Lab 1-3: Naive Bayes classification"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
